ID,Sender,SenderName,Content,Timestamp,Duration,Offset
"3988","Guest-1","Developer(Vector Database Researcher)","Um, hello, recently I've been researching vector databases so I tried out Pinecone.","2025-01-17T19:33:15+08:00","10720","1510"
"3989","Guest-1","Developer(Vector Database Researcher)","Um, Pinecone, how do you spell it? It's PINECONE.","2025-01-17T19:33:23+08:00","7160","13390"
"3991","Guest-1","Developer(Vector Database Researcher)","I'm doing a very professional introduction and horizontal evaluation of vector databases.","2025-01-17T19:33:41+08:00","4920","33880"
"3992","Guest-1","Developer(Vector Database Researcher)","Just from a traditional database developer's perspective to understand vector databases, and why vector databases currently...","2025-01-17T19:33:54+08:00","11680","39510"
"3993","Guest-1","Developer(Vector Database Researcher)","are receiving so much attention and a relatively high valuation in the financing market.","2025-01-17T19:34:06+08:00","9880","52150"
"3996","Guest-1","Developer(Vector Database Researcher)","Some insights - first, let me simply define what a vector database is. From a pure developer's perspective, vector databases mainly solve a similarity problem.","2025-01-17T19:34:27+08:00","14160","70510"
"3998","Guest-1","Developer(Vector Database Researcher)","Like the early Elasticsearch model, it was doing some word-based full-text retrieval, and its understanding of words might primarily be just tokenization, nothing beyond that.","2025-01-17T19:34:45+08:00","15440","87470"
"3999","Guest-1","Developer(Vector Database Researcher)","Let me give an example, like in a traditional Elasticsearch - though I should first clarify that Elasticsearch has also made many improvements in vector databases. When I say Elasticsearch, I'm mainly referring to traditional Elasticsearch.","2025-01-17T19:35:05+08:00","18560","103900"
"4000","Guest-1","Developer(Vector Database Researcher)","Not implying anything about features they added later. OK, back to the topic.","2025-01-17T19:35:15+08:00","7880","123070"
"4001","Guest-1","Developer(Vector Database Researcher)","For a traditional full-text search database, to use that as an example, for...","2025-01-17T19:35:20+08:00","5120","132520"
"4002","Guest-1","Developer(Vector Database Researcher)","searching some words, it mainly does word matching, at most doing normalization for case sensitivity. For example, if I search for...","2025-01-17T19:35:33+08:00","12080","138430"
"4003","Guest-1","Developer(Vector Database Researcher)","Microsoft Cloud.","2025-01-17T19:35:36+08:00","1440","151350"
"4005","Guest-1","Developer(Vector Database Researcher)","If Microsoft or Cloud were mentioned in previous full-text retrieval indexes, then after tokenization, it might find Microsoft Cloud, or just Microsoft.","2025-01-17T19:35:52+08:00","12040","157120"
"4006","Guest-1","Developer(Vector Database Researcher)","Or just Cloud. But if what's mentioned in the index is Azure.","2025-01-17T19:36:01+08:00","8320","169790"
"4007","Guest-1","Developer(Vector Database Researcher)","Then generally this kind of search engine can't retrieve related content, and a typical full-text search database wouldn't find Azure.","2025-01-17T19:36:16+08:00","13480","179470"
"4008","Guest-1","Developer(Vector Database Researcher)","Now, based on language models - note that I'm saying language models, not large language models, because many people have a misconception that vector databases must use large language models for embeddings.","2025-01-17T19:36:37+08:00","18600","195870"
"4009","Guest-1","Developer(Vector Database Researcher)","I'll explain what embeddings are later.","2025-01-17T19:36:41+08:00","2920","215310"
"4010","Guest-1","Developer(Vector Database Researcher)","Hmm, for, hmm.","2025-01-17T19:36:52+08:00","9120","219310"
"4011","Guest-1","Developer(Vector Database Researcher)","Embeddings were a major innovation by Google in the machine learning field, invented quite early, and then...","2025-01-17T19:37:08+08:00","14360","230830"
"4012","Guest-1","Developer(Vector Database Researcher)","were rediscovered after the rise of recommendation systems.","2025-01-17T19:37:16+08:00","6360","246090"
"4013","Guest-1","Developer(Vector Database Researcher)","OK, we'll talk about embeddings later.","2025-01-17T19:37:20+08:00","1440","254840"
"4015","Guest-1","Developer(Vector Database Researcher)","Then.","2025-01-17T19:37:23+08:00","720","259430"
"4016","Guest-1","Developer(Vector Database Researcher)","I first tried this, and I should mention that I'm a traditional database developer with some machine learning experience, previously working on machine learning platforms at Shopify.","2025-01-17T19:37:37+08:00","12680","261830"
"4017","Guest-1","Developer(Vector Database Researcher)","So I have some understanding of both data and machine learning.","2025-01-17T19:37:41+08:00","3040","274670"
"4018","Guest-1","Developer(Vector Database Researcher)","OK, let's continue, remind me later to add more about this.","2025-01-17T19:50:47+08:00","5840","1470"
"4019","Guest-1","Developer(Vector Database Researcher)","Related to this, for instance, Pinecone uses a multilingual E5 large model by default.","2025-01-17T19:51:01+08:00","11720","8830"
"4020","Guest-1","Developer(Vector Database Researcher)","Its CPU inference...","2025-01-17T19:51:02+08:00","1840","22120"
"4021","Guest-1","Developer(Vector Database Researcher)","speed compared to GPU inference speed, roughly looking at it, this model is just a 24-layer model with only about 560 million parameters.","2025-01-17T19:51:20+08:00","16040","24990"
"4022","Guest-1","Developer(Vector Database Researcher)","Based on information online, it uses about 3GB of memory, so I would roughly guess that its inference speed should be quite fast even with CPU inference.","2025-01-17T19:51:38+08:00","17520","42430"
"4023","Guest-1","Developer(Vector Database Researcher)","What I mainly want to point out here is that many people think vector databases became popular because of large models.","2025-01-17T19:51:54+08:00","13360","60920"
"4024","Guest-1","Developer(Vector Database Researcher)","Um.","2025-01-17T19:51:57+08:00","480","76640"
"4025","Guest-1","Developer(Vector Database Researcher)","RAG.","2025-01-17T19:51:59+08:00","800","79240"
"4026","Guest-1","Developer(Vector Database Researcher)","Driven by the rise of RAG.","2025-01-17T19:52:06+08:00","3880","82350"
"4027","Guest-1","Developer(Vector Database Researcher)","So many people were first amazed by ChatGPT and other large model providers like Claude, then they learned about RAG, and then they discovered...","2025-01-17T19:52:20+08:00","14000","87800"
"4028","Guest-1","Developer(Vector Database Researcher)","vector databases.","2025-01-17T19:52:22+08:00","920","102310"
"4029","Guest-1","Developer(Vector Database Researcher)","So.","2025-01-17T19:52:28+08:00","3200","106060"
"4030","Guest-1","Developer(Vector Database Researcher)","This created a somewhat incorrect impression, and companies like OpenAI are deliberately guiding users to believe that...","2025-01-17T19:52:41+08:00","10720","110390"
"4031","Guest-1","Developer(Vector Database Researcher)","Based on text...","2025-01-17T19:52:43+08:00","2160","122840"
"4032","Guest-1","Developer(Vector Database Researcher)","generating embeddings requires a very large model or even calling their services. Those with experience know that using OpenAI's service to generate embeddings can create a huge bill.","2025-01-17T19:53:00+08:00","15520","125670"
"4033","Guest-1","Developer(Vector Database Researcher)","But what I really want everyone to understand is that for language model embedding generation, even for multilingual language models,","2025-01-17T19:53:17+08:00","15680","142390"
"4034","Guest-1","Developer(Vector Database Researcher)","to achieve production-ready results like the multilingual E5 Text large model that Pinecone recommends,","2025-01-17T19:53:27+08:00","8400","158710"
"4035","Guest-1","Developer(Vector Database Researcher)","you can simply use a CPU to generate embeddings.","2025-01-17T19:53:32+08:00","4320","168880"
"4036","Guest-1","Developer(Vector Database Researcher)","to achieve usable results.","2025-01-17T19:53:35+08:00","1560","173950"
"4037","Guest-1","Developer(Vector Database Researcher)","It's just that if you're doing batch insertion, generating embeddings - say generating embeddings for 128 sentences at once, forming a very large batch - then using a GPU would be...","2025-01-17T19:54:00+08:00","22960","177790"
"4038","Guest-1","Developer(Vector Database Researcher)","much faster than using a CPU.","2025-01-17T19:54:02+08:00","1480","201600"
"4039","Guest-1","Developer(Vector Database Researcher)","Of course, since the memory requirements are low, just within 3GB, even outdated GPUs like the 2060 can easily handle this kind of batch text embedding generation.","2025-01-17T19:54:20+08:00","16960","204030"
"4040","Guest-1","Developer(Vector Database Researcher)","And with multilingual support too.","2025-01-17T19:54:22+08:00","1840","221430"
"4041","Guest-1","Developer(Vector Database Researcher)","While trying out Pinecone recently, I found that many people...","2025-01-17T19:54:35+08:00","9160","225460"
"4042","Guest-1","Developer(Vector Database Researcher)","who understand vector indexing would think that vector databases must use...","2025-01-17T19:54:46+08:00","9840","236160"
"4043","Guest-1","Developer(Vector Database Researcher)","similarity retrieval like ANN (Approximate Nearest Neighbor).","2025-01-17T19:54:53+08:00","5880","247680"
"4044","Guest-1","Developer(Vector Database Researcher)","to be capable. But when I was using Pinecone, I wasn't clear whether it uses ANN or more advanced techniques like disk embeddings.","2025-01-17T19:55:07+08:00","14160","254790"
"4045","Guest-1","Developer(Vector Database Researcher)","This kind of...","2025-01-17T19:55:11+08:00","1560","269470"
"4046","Guest-1","Developer(Vector Database Researcher)","Is it disk embeddings? I forgot, need to check that later, remind me.","2025-01-17T19:55:20+08:00","6880","272600"
"4047","Guest-1","Developer(Vector Database Researcher)","Um.","2025-01-17T19:55:22+08:00","560","281480"
"4048","Guest-1","Developer(Vector Database Researcher)","From my experience with Pinecone, I didn't feel they had very sophisticated or complex embedding vector retrieval algorithms like...","2025-01-17T19:55:38+08:00","15160","283910"
"4049","Guest-1","Developer(Vector Database Researcher)","like Facebook's FAISS and Google's - what's Google's called? Forgot, need to check that too.","2025-01-17T19:55:45+08:00","7080","299630"
"4050","Guest-1","Developer(Vector Database Researcher)","like those library integrations, so actually, in many...","2025-01-17T19:55:55+08:00","7840","307630"
"4051","Guest-1","Developer(Vector Database Researcher)","application scenarios, brute force search is actually enough to...","2025-01-17T19:56:02+08:00","5640","317310"
"4052","Guest-1","Developer(Vector Database Researcher)","complete this.","2025-01-17T19:56:05+08:00","1520","324110"
"4053","Guest-1","Developer(Vector Database Researcher)","vector database retrieval work.","2025-01-17T19:56:09+08:00","3360","326750"
"4054","Guest-1","Developer(Vector Database Researcher)","The general process is like this: first, you batch generate embeddings for some text, then you insert both the text itself and its embedding into the database. Then, you take another sentence, which might be a question in a Q&A system.","2025-01-17T19:56:36+08:00","24200","332600"
"4055","Guest-1","Developer(Vector Database Researcher)","Then without any special processing, you directly generate an embedding for this sentence using the same embedding generation algorithm, and then do cosine distance retrieval based on this embedding. You can completely use brute force search.","2025-01-17T19:56:50+08:00","14360","357270"
"4056","Guest-1","Developer(Vector Database Researcher)","Directly brute force search the cosine distance between this embedding and all other embeddings in the database, find the closest ones, and this can complete a similarity retrieval.","2025-01-17T19:57:04+08:00","13240","371830"
"4057","Guest-1","Developer(Vector Database Researcher)","This is a common retrieval scenario nowadays. Although I'm mainly talking about language models generating embeddings from text, image-based approaches are similar.","2025-01-17T19:57:19+08:00","13280","387080"
"4058","Guest-1","Developer(Vector Database Researcher)","It's just that because images have a larger input vector range, generally if you're doing vector retrieval based on images, you definitely need a GPU, but not a particularly advanced one, just...","2025-01-17T19:57:41+08:00","20920","400990"
"4059","Guest-1","Developer(Vector Database Researcher)","entry-level, like the GPUs used before the rise of large language models - ordinary graphics cards can handle it.","2025-01-17T19:57:54+08:00","12120","422670"
"4060","Guest-1","Developer(Vector Database Researcher)","OK, what else?","2025-01-17T19:58:01+08:00","4840","437540"
"4061","Guest-1","Developer(Vector Database Researcher)","Another interesting point is that when using Pinecone, I found that they intentionally or unintentionally encourage you to use higher dimensions to store your vectors. Their default dimension is 1024.","2025-01-17T19:58:32+08:00","24800","448280"
"4062","Guest-1","Developer(Vector Database Researcher)","But through my simple evaluation, based on, for example, their...","2025-01-17T19:58:44+08:00","9560","474020"
"4063","Guest-1","Developer(Vector Database Researcher)","generated sequence length, the one-time input token length is only around 500 to 1000.","2025-01-17T19:58:53+08:00","7280","485230"
"4064","Guest-1","Developer(Vector Database Researcher)","Based on sentences of this length, even if you store millions of records...","2025-01-17T19:58:59+08:00","5760","494230"
"4065","Guest-1","Developer(Vector Database Researcher)","a 256-dimensional embedding would achieve very good results - you don't need 1024 dimensions at all.","2025-01-17T19:59:09+08:00","9920","500940"
"4066","Guest-1","Developer(Vector Database Researcher)","But you know these databases charge based on usage, so higher dimensions mean higher usage. So this is understandable.","2025-01-17T19:59:22+08:00","12320","511420"
"4067","Guest-1","Developer(Vector Database Researcher)","Hmm.","2025-01-17T19:59:29+08:00","120","527990"
"4068","Guest-1","Developer(Vector Database Researcher)","But one praiseworthy point is... Let me first explain what I imagine a user-friendly vector database model would be like. First, I think embeddings shouldn't exist as a...","2025-01-17T19:59:59+08:00","24040","535260"
"4069","Guest-1","Developer(Vector Database Researcher)","column or as a data form in the database.","2025-01-17T20:00:02+08:00","3080","560110"
"4070","Guest-1","Developer(Vector Database Researcher)","It should exist as a special index, similar to how I insert a bunch of text, and then I can create an index on this text column, with the index mode set to...","2025-01-17T20:00:18+08:00","15480","563980"
"4071","Guest-1","Developer(Vector Database Researcher)","embedding, and then when retrieving, use text to find similar calculations, like the statement...","2025-01-17T20:00:30+08:00","8960","581140"
"4072","Guest-1","Developer(Vector Database Researcher)","SELECT text FROM text_table","2025-01-17T20:00:34+08:00","3640","591670"
"4073","Guest-1","Developer(Vector Database Researcher)","WHERE input_text","2025-01-17T20:00:37+08:00","2160","595900"
"4074","Guest-1","Developer(Vector Database Researcher)","EMBEDDING LIKE","2025-01-17T20:00:40+08:00","1440","599100"
"4075","Guest-1","Developer(Vector Database Researcher)","text, something like that?","2025-01-17T20:00:45+08:00","3480","602100"
"4076","Guest-1","Developer(Vector Database Researcher)","Users shouldn't be aware of embeddings at all. When inserting data, embeddings would be calculated automatically, and when retrieving, the embedding of the input sentence would be calculated naturally, then similarity retrieval performed, followed by ORDER BY LIMIT.","2025-01-17T20:01:03+08:00","17200","607150"
"4077","Guest-1","Developer(Vector Database Researcher)","Then retrieve, for example, the top 5 similar results.","2025-01-17T20:01:06+08:00","2920","624620"
"4078","Guest-1","Developer(Vector Database Researcher)","That would be better.","2025-01-17T20:01:09+08:00","1280","628340"
"4079","Guest-1","Developer(Vector Database Researcher)","Hmm.","2025-01-17T20:01:17+08:00","120","635150"
"4080","Guest-1","Developer(Vector Database Researcher)","Another interesting point is...","2025-01-17T20:01:24+08:00","2080","642600"
"4081","Guest-1","Developer(Vector Database Researcher)","Pinecone's partnership model with cloud providers like AWS, GCP, and Azure is interesting. I tried their partnership with Azure.","2025-01-17T20:01:36+08:00","11120","646230"
"4082","Guest-1","Developer(Vector Database Researcher)","Because they're in Azure's marketplace, when you use Pinecone and link your Azure account, they can charge directly to your Azure account.","2025-01-17T20:01:49+08:00","12200","658100"
"4083","Guest-1","Developer(Vector Database Researcher)","This provides a big advantage for consolidated payments in enterprises.","2025-01-17T20:01:54+08:00","4320","670540"
"4084","Guest-1","Developer(Vector Database Researcher)","Hmm.","2025-01-17T20:01:58+08:00","320","675980"
"4085","Guest-1","Developer(Vector Database Researcher)","Another point is that their getting started guide is well done, from the beginning...","2025-01-17T20:02:14+08:00","12160","682820"
"4086","Guest-1","Developer(Vector Database Researcher)","Choosing a language, providing sample code, selecting embedding models, and giving you code for insertion and querying - the experience is quite good.","2025-01-17T20:02:28+08:00","13640","695460"
"4087","Guest-1","Developer(Vector Database Researcher)","But still...","2025-01-17T20:02:34+08:00","2560","711770"
"4088","Guest-1","Developer(Vector Database Researcher)","You need some understanding of embeddings and related concepts to build a good application.","2025-01-17T20:02:47+08:00","12280","715950"
